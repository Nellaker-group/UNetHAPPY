from pathlib import Path
import json
import uuid

import pandas as pd
import typer
from tqdm import tqdm
from labelbox import Client, Project, Dataset
from labelbox.schema.ontology import OntologyBuilder


def main(
    project_name: str = typer.Option(...),
    labelbox_project_name: str = typer.Option(...),
    json_filename: str = typer.Option(...),
    dataset_name: str = typer.Option(...),
    import_job_name: str = typer.Option(...),
    include_labels: bool = False,
):
    """Converts QuPath extracted json file of tissue annotation polygons from global
    coordinates to local coordinates (coords relative to image tile) and uploads
    them to LabelBox as 'pre-labels'.

    Args:
        project_name: name of the project directory
        labelbox_project_name: name of project in LabelBox
        json_filename: path to json file generated by QuPath script
        dataset_name: name of dataset in LabelBox to apply annotations to
        import_job_name: name of import/upload job to be displayed in LabelBox
        include_labels: flag for including original tissue label or not
    """
    with open("./config.json") as f:
        api_key = json.load(f)["LabelBoxAPIKey"]
    lb = Client(api_key)
    projects = lb.get_projects(where=Project.name == labelbox_project_name)
    project = next(projects)
    ontology = OntologyBuilder.from_project(project)
    schema_lookup = {tool.name: tool.feature_schema_id for tool in ontology.tools}

    datasets = lb.get_datasets(where=Dataset.name == dataset_name)
    dataset = next(datasets)

    projects_dir = Path(__file__).parent.parent / "projects"
    save_dir = projects_dir / project_name / "results" / "tissue_annots"

    with open(save_dir / json_filename) as f:
        data = json.load(f)

    final_data = []
    for annotation in tqdm(data):
        datarow = dataset.data_row_for_external_id(annotation["image_name"])
        labelbox_image_uid = datarow.uid
        datarow_data = {"id": labelbox_image_uid}
        local_polygon_coords = []

        image_name = annotation["image_name"]
        name_parts = image_name.split(".")[0].split("_")
        xmin = int(name_parts[1].split("x")[1])
        ymin = int(name_parts[2].split("y")[1])
        coordinates = annotation["coordinates"]

        try:
            downsample_factor = annotation["downsample"]
        except KeyError:
            print("Downsample factor being calculated.")
            downsample_factor = calc_downsample_factor(coordinates)

        for point in coordinates:
            local_x, local_y = global_coord_to_local(xmin, ymin, point["x"], point["y"])
            local_x += 250
            local_y += 250
            local_x = round(local_x / downsample_factor, 3)
            local_y = round(local_y / downsample_factor, 3)
            local_polygon_coords.append({"x": local_x, "y": local_y})

        final_dict = {
            "uuid": str(uuid.uuid4()),
            "schemaId": get_schema_id(
                schema_lookup, include_labels, annotation["tissue_type"]
            ),
            "dataRow": datarow_data,
            "polygon": local_polygon_coords,
        }
        final_data.append(final_dict)

    upload_job = project.upload_annotations(
        name=import_job_name, annotations=final_data
    )
    upload_job.wait_until_done()
    print("State", upload_job.state)

# Only used if it isn't found in annotations. Kept for old annotation files.
def calc_downsample_factor(coordinates):
    coordinates = pd.DataFrame(coordinates)
    xmin = coordinates["x"].min()
    xmax = coordinates["x"].max()
    ymin = coordinates["y"].min()
    ymax = coordinates["y"].max()
    width = xmax - xmin
    height = ymax - ymin
    if width >= 5000:
        return 4
    elif width <= 200:
        return 1
    elif height <= 200:
        return 1
    return 1.5


def global_coord_to_local(xmin, ymin, x, y):
    if x == 0 and y == 0:
        return 0, 0
    if x == 0:
        return 0, y - ymin
    if y == 0:
        return x - xmin, 0
    return x - xmin, y - ymin


def get_schema_id(schema_lookup, include_labels, tissue_label=None):
    if not include_labels:
        return schema_lookup["Unlabeled"]
    else:
        return schema_lookup[TISSUE_TYPE_MAP[tissue_label]]


TISSUE_TYPE_MAP = {
    "TVilli": "Terminal Villi",
    "MIVilli": "Mature Intermediary Villi",
    "ImIVilli": "Immature Intermediary Villi",
    "SVilli": "Stem Villi",
    "AVilli": "Anchoring Villi",
    "MVilli": "Mesenchymal Villi",
    "Sprout": "Villus Sprout",
    "Chorion": "Chorion/Amnion",
    "Avascular": "Avascular Villi",
    "Maternal": "Basal Plate/Septa",
    "Fibrin": "Fibrin",
    "Inflam": "Inflammatory Response",
}

if __name__ == "__main__":
    typer.run(main)
